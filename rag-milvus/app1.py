import streamlit as st
# ---------- é¡µé¢é…ç½® ----------
st.set_page_config(page_title="RAG å°åŠ©æ‰‹", layout="wide")
from pathlib import Path
import asyncio
from rag.retriever import astream_simple,astream_answer_his
from langchain_community.document_loaders import TextLoader, PyPDFLoader, Docx2txtLoader
from langchain_text_splitters import CharacterTextSplitter
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_milvus import Milvus



# ---------- è·¯å¾„ ----------
DATA_DIR = Path("data")
DATA_DIR.mkdir(exist_ok=True)

# # ---------- åªå»ºä¸€æ¬¡ embedding & milvus ----------
# @st.cache_resource
# def get_milvus():
#     embed = HuggingFaceEmbeddings(
#         model_name="/home/wzy/pyfile/rag-milvus/model/bge-base-zh-v1.5",
#         encode_kwargs={"normalize_embeddings": True}
#     )
#     return Milvus(
#         embedding_function=embed,
#         collection_name="policy_chunks",
#         connection_args={"uri": "milvus_demo.db"},
#         index_params={"index_type": "FLAT", "metric_type": "IP"},
#
#     )
#
# milvus = get_milvus()


# ---------- å·¦ä¾§ï¼šç›®å½•æ ‘ ----------


# ---------- æ–‡ä»¶ä¸Šä¼  ----------
def load_single_file(path: Path):
    suffix = path.suffix.lower()
    if suffix == ".pdf":
        return PyPDFLoader(str(path)).load()
    if suffix in (".docx", ".doc"):
        return Docx2txtLoader(str(path)).load()
    return TextLoader(str(path), encoding="utf-8").load()

def uploader_fragment():
    st.markdown("### ğŸ“¤ æ–‡ä»¶ä¸Šä¼ ")
    uploaded = st.file_uploader(
        "æ”¯æŒ pdf/docx/txt/mdï¼ˆå¯å¤šé€‰ï¼‰",
        type=["pdf", "docx", "doc", "txt", "md"],
        accept_multiple_files=True
    )
    if st.button("åŠ è½½åˆ°çŸ¥è¯†åº“", type="primary"):
        if not uploaded:
            st.warning("è¯·å…ˆä¸Šä¼ æ–‡ä»¶")
        else:
            data_dir = Path("data")
            data_dir.mkdir(exist_ok=True)
            for f in uploaded:
                save_path = data_dir / f.name
                with open(save_path, "wb") as tmp:
                    tmp.write(f.getbuffer())
            with st.spinner("è§£æ+å‘é‡åŒ–ä¸­ï¼Œè¯·ç¨å€™..."):
                import subprocess
                result = subprocess.run(
                    ["python", "scripts/build_with_langchain.py"],
                    capture_output=True,
                    text=True
                )
            if result.returncode != 0:
                st.error("è„šæœ¬è¿è¡Œå¤±è´¥ï¼Œè¯¦æƒ…å¦‚ä¸‹ï¼š")
                st.code(result.stdout + result.stderr, language="bash")
            else:
                st.success("âœ… å·²å…¨éƒ¨å…¥åº“ï¼Œå¯ä»¥æé—®äº†ï¼")
    # if st.button("åŠ è½½åˆ°çŸ¥è¯†åº“", type="primary"):
    #     if not uploaded:
    #         st.error("è¯·å…ˆä¸Šä¼ æ–‡ä»¶"); return
    #     prog = st.progress(0)
    #     for idx, file in enumerate(uploaded, 1):
    #         save_path = DATA_DIR / file.name
    #         save_path.write_bytes(file.read())
    #         docs = load_single_file(save_path)
    #         chunks = CharacterTextSplitter(chunk_size=512, chunk_overlap=64).split_documents(docs)
    #         # âœ… ä¿®å¤ï¼šå¼ºåˆ¶è¡¥ metadata å­—æ®µ
    #         for ch in chunks:
    #             ch.metadata = ch.metadata or {}
    #             ch.metadata.setdefault("source", "")
    #
    #         milvus.add_documents(chunks)
    #         prog.progress(idx / len(uploaded))
    #         st.text(f"âœ… {file.name}  å…± {len(chunks)} æ®µ")
    #     st.success("å…¨éƒ¨åŠ è½½å®Œæˆï¼")
    #     st.rerun()   # ç«‹å³åˆ·æ–°å·¦ä¾§ç›®å½•æ ‘

# ---------- è¿ç»­å¯¹è¯ ----------
async def generate_answer(question: str):
    sources = set()
    async for delta, src in astream_simple(question):
        sources |= src
        yield delta, sources     # ç›´æ¥ç»™æœ€æ–°å®Œæ•´å­—ç¬¦ä¸²

def main_chat():
    st.markdown("### ğŸ’¬ è¿ç»­å¯¹è¯")
    if "history" not in st.session_state:
        st.session_state.history = []
        # --- å±•ç¤ºå†å²ï¼ˆä»…å‰ç«¯æ˜¾ç¤ºï¼Œä¸å†æ‹¼åˆ° promptï¼‰ ---
    for role, msg in st.session_state.history:
        with st.chat_message(role):
            st.markdown(msg)

    # 2. åº•éƒ¨å›ºå®šè¾“å…¥æ¡†
    with st.container():
        # è®©è¾“å…¥æ¡†å§‹ç»ˆè´´åœ¨åº•éƒ¨
        question = st.chat_input("è¯·è¾“å…¥é—®é¢˜")
    if question :
        # 1. å‰ç«¯ç«‹å³æ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯
        st.session_state.history.append(("user", question))
        with st.chat_message("user"):
            st.markdown(question)

        # 2. ***åªæŠŠå½“å‰é—®é¢˜é€ç»™æ¨¡å‹***ï¼ˆæ— å†å²æ‹¼æ¥ï¼‰
        full_prompt = question

        # 3. æµå¼ç”Ÿæˆå›ç­”
        with st.chat_message("assistant"):
            placeholder = st.empty()
            answer, sources = "", set()

            def sync_gen():
                loop = asyncio.new_event_loop()
                gen = astream_answer_his(st.session_state.history, question)
                #gen = generate_answer(full_prompt)

                while True:
                    try:
                        delta, src = loop.run_until_complete(gen.__anext__())
                        yield delta, src
                    except StopAsyncIteration:
                        break

            for delta, src in sync_gen():
                #answer = delta
                answer += delta
                sources |= src
                placeholder.markdown(answer)

            if sources:
                answer += f"\n\nğŸ“ æ¥æºï¼š{', '.join(sources)}"
                placeholder.markdown(answer)

        # 4. æŠŠå›ç­”è®°å…¥å‰ç«¯å†å²ï¼ˆä»…æ˜¾ç¤ºï¼Œä¸ç”¨äºä¸‹ä¸€è½® promptï¼‰
        st.session_state.history.append(("assistant", answer))


# ---------- å¸ƒå±€ ----------
col1, col2 = st.columns([1, 3])
with col1:
    st.markdown("### ğŸ“ data ç›®å½•")
    if DATA_DIR.exists():
        # æ ¹ç›®å½•æ–‡ä»¶é»˜è®¤å±•å¼€
        root_files = [f for f in DATA_DIR.iterdir() if f.is_file()]
        if root_files:
            with st.expander("ğŸ“„ æ ¹ç›®å½•æ–‡ä»¶", expanded=True):
                for f in sorted(root_files):
                    st.text(f.name)

        # å­æ–‡ä»¶å¤¹é»˜è®¤å±•å¼€
        for d in sorted(DATA_DIR.iterdir()):
            if d.is_dir():
                with st.expander(f"ğŸ“‚ {d.name}", expanded=True):
                    for f in sorted(d.iterdir()):
                        if f.is_file():
                            st.text(f.name)
    else:
        st.warning("ç›®å½• ./data ä¸å­˜åœ¨")

    st.divider()
    uploader_fragment()
with col2:
    main_chat()